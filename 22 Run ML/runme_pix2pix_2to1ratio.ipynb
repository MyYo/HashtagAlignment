{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Run Pix2Pix\n",
    "This notebook is optimized for using pytorch (look at the environment on the top right). <br>\n",
    "This is the main folder path: [~/ml/](http://localhost:8888/tree/ml)<br>\n",
    "Image dataset is located here: [~/ml/dataset_oct_histology/](http://localhost:8888/tree/ml/dataset_oct_histology)<br>\n",
    "[Github Link](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)<br>\n",
    "<br>\n",
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (20.1.1)\n",
      "Requirement already satisfied: opencv-python in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from opencv-python) (1.18.1)\n",
      "Cloning into '/home/ubuntu/ml/pix2pix_and_CycleGAN'...\n",
      "remote: Enumerating objects: 2262, done.\u001b[K\n",
      "remote: Total 2262 (delta 0), reused 0 (delta 0), pack-reused 2262\u001b[K\n",
      "Receiving objects: 100% (2262/2262), 8.06 MiB | 26.88 MiB/s, done.\n",
      "Resolving deltas: 100% (1456/1456), done.\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from -r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from -r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: dominate>=2.3.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from -r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 3)) (2.5.1)\n",
      "Requirement already satisfied: visdom>=0.1.8.3 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from -r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (0.1.8.9)\n",
      "Requirement already satisfied: future in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from torch>=0.4.1->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 1)) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from torch>=0.4.1->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from torchvision>=0.2.1->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 2)) (6.2.2)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from torchvision>=0.2.1->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 2)) (1.11.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (2.20.0)\n",
      "Requirement already satisfied: pyzmq in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (17.0.0)\n",
      "Requirement already satisfied: torchfile in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (0.1.0)\n",
      "Requirement already satisfied: websocket-client in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (0.57.0)\n",
      "Requirement already satisfied: jsonpatch in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (1.25)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: tornado in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (5.0.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (1.23)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from requests->visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (2019.11.28)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages (from jsonpatch->visdom>=0.1.8.3->-r /home/ubuntu/ml/pix2pix_and_CycleGAN/requirements.txt (line 4)) (2.0)\n"
     ]
    }
   ],
   "source": [
    "# Set up general varibles\n",
    "root_path = '~/ml/'\n",
    "dataset_path = root_path + 'dataset_oct_histology/'\n",
    "code_main_folder = root_path + 'pix2pix_and_CycleGAN/'\n",
    "\n",
    "# Install environment dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install opencv-python\n",
    "\n",
    "# Clear code, start a fresh copy\n",
    "import shutil\n",
    "import os\n",
    "if os.path.isdir(os.path.expanduser(code_main_folder)):\n",
    "    shutil.rmtree(os.path.expanduser(code_main_folder))\n",
    "    \n",
    "# Get main model\n",
    "!git clone --single-branch https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix {code_main_folder}\n",
    "!pip install -r {code_main_folder}requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset\n",
    "This library requires OCT and histology images to be paired together.<br>\n",
    "Code below merges images from  [patches_256px_256px](http://localhost:8888/tree/ml/dataset_oct_histology/patches_256px_256px) to [patches_256px_256px_combined](http://localhost:8888/tree/ml/dataset_oct_histology/patches_256px_256px_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_combine_aux_functions\n",
    "\n",
    "# Define train & test patches folders\n",
    "train_patches_folder = dataset_path + 'patches_256px_256px_aspect_ratio_2_1/'\n",
    "train_patches_folder_combined = train_patches_folder[:-1] + '_combined/'\n",
    "test_patches_folder = dataset_path + 'patches_256px_256px_aspect_ratio_2_1/'\n",
    "test_patches_folder_combined = test_patches_folder[:-1] + '_combined/'\n",
    "\n",
    "# Generate combine train dataset of A and B\n",
    "image_combine_aux_functions.combine_images(\n",
    "    img_fold_A = (train_patches_folder + 'train_A/'),\n",
    "    img_fold_B = (train_patches_folder + 'train_B/'),\n",
    "    img_fold_AB = (train_patches_folder_combined + 'train/'))\n",
    "\n",
    "# Make sure that in train_patches_folder_combined there is no test folder.\n",
    "# This prevents mistake leakage of data.\n",
    "image_combine_aux_functions.clear_dir(train_patches_folder_combined + 'test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Run code below to train model.<br>\n",
    "Results can be viewed here: [~/ml/checkpoints/pix2pix_2to1ratio/web/index.html](http://localhost:8888/view/ml/checkpoints/pix2pix_2to1ratio/web/index.html) as the model trains.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: /home/ubuntu/ml/checkpoints   \t[default: ./checkpoints]\n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /home/ubuntu/ml/dataset_oct_histology/patches_256px_256px_aspect_ratio_2_1_combined/\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: pix2pix_2to1ratio             \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: False                         \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 211\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n",
      "Setting up a new session...\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/connection.py\", line 171, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/util/connection.py\", line 79, in create_connection\n",
      "    raise err\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/util/connection.py\", line 69, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/http/client.py\", line 1239, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/http/client.py\", line 1285, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/http/client.py\", line 1234, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/http/client.py\", line 964, in send\n",
      "    self.connect()\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/connection.py\", line 196, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/connection.py\", line 180, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f4e7935ce48>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/urllib3/util/retry.py\", line 398, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4e7935ce48>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/requests/sessions.py\", line 572, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/requests/sessions.py\", line 524, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/requests/sessions.py\", line 637, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4e7935ce48>: Failed to establish a new connection: [Errno 111] Connection refused',))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Could not connect to Visdom server. \n",
      " Trying to start a server....\n",
      "Command: /home/ubuntu/anaconda3/envs/aws_neuron_pytorch_p36/bin/python -m visdom.server -p 8097 &>/dev/null &\n",
      "create web directory /home/ubuntu/ml/checkpoints/pix2pix_2to1ratio/web...\n",
      "(epoch: 1, iters: 100, time: 0.100, data: 0.639) G_GAN: 2.457 G_L1: 24.144 D_real: 0.048 D_fake: 0.522 \n",
      "(epoch: 1, iters: 200, time: 0.099, data: 0.001) G_GAN: 3.370 G_L1: 21.292 D_real: 0.078 D_fake: 0.195 \n",
      "End of epoch 1 / 200 \t Time Taken: 14 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 2, iters: 89, time: 0.101, data: 0.001) G_GAN: 3.019 G_L1: 23.632 D_real: 0.030 D_fake: 0.195 \n",
      "(epoch: 2, iters: 189, time: 0.299, data: 0.001) G_GAN: 2.623 G_L1: 22.070 D_real: 0.157 D_fake: 0.156 \n",
      "End of epoch 2 / 200 \t Time Taken: 12 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 3, iters: 78, time: 0.101, data: 0.001) G_GAN: 3.097 G_L1: 17.196 D_real: 0.056 D_fake: 0.399 \n",
      "(epoch: 3, iters: 178, time: 0.101, data: 0.001) G_GAN: 2.881 G_L1: 32.487 D_real: 0.051 D_fake: 0.200 \n",
      "End of epoch 3 / 200 \t Time Taken: 12 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 4, iters: 67, time: 0.101, data: 0.001) G_GAN: 2.195 G_L1: 21.803 D_real: 0.113 D_fake: 0.188 \n",
      "(epoch: 4, iters: 167, time: 0.281, data: 0.001) G_GAN: 1.995 G_L1: 31.553 D_real: 0.019 D_fake: 0.564 \n",
      "End of epoch 4 / 200 \t Time Taken: 12 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 5, iters: 56, time: 0.102, data: 0.001) G_GAN: 2.433 G_L1: 29.050 D_real: 0.145 D_fake: 0.100 \n",
      "(epoch: 5, iters: 156, time: 0.102, data: 0.001) G_GAN: 1.618 G_L1: 23.034 D_real: 0.210 D_fake: 0.380 \n",
      "saving the model at the end of epoch 5, iters 1055\n",
      "End of epoch 5 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 6, iters: 45, time: 0.101, data: 0.001) G_GAN: 2.204 G_L1: 23.077 D_real: 0.093 D_fake: 0.231 \n",
      "(epoch: 6, iters: 145, time: 0.232, data: 0.001) G_GAN: 2.032 G_L1: 20.245 D_real: 0.810 D_fake: 0.088 \n",
      "End of epoch 6 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 7, iters: 34, time: 0.103, data: 0.001) G_GAN: 3.333 G_L1: 20.994 D_real: 0.015 D_fake: 2.225 \n",
      "(epoch: 7, iters: 134, time: 0.103, data: 0.001) G_GAN: 3.611 G_L1: 24.297 D_real: 0.050 D_fake: 0.051 \n",
      "End of epoch 7 / 200 \t Time Taken: 12 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 8, iters: 23, time: 0.103, data: 0.001) G_GAN: 1.571 G_L1: 22.843 D_real: 1.186 D_fake: 0.099 \n",
      "(epoch: 8, iters: 123, time: 0.236, data: 0.001) G_GAN: 0.844 G_L1: 18.851 D_real: 0.643 D_fake: 0.491 \n",
      "End of epoch 8 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 9, iters: 12, time: 0.103, data: 0.001) G_GAN: 2.105 G_L1: 21.976 D_real: 0.231 D_fake: 0.626 \n",
      "(epoch: 9, iters: 112, time: 0.103, data: 0.001) G_GAN: 2.804 G_L1: 25.982 D_real: 0.099 D_fake: 0.071 \n",
      "End of epoch 9 / 200 \t Time Taken: 12 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 10, iters: 1, time: 0.059, data: 0.001) G_GAN: 2.416 G_L1: 23.715 D_real: 0.009 D_fake: 0.557 \n",
      "(epoch: 10, iters: 101, time: 0.237, data: 0.002) G_GAN: 1.577 G_L1: 22.415 D_real: 0.021 D_fake: 0.444 \n",
      "(epoch: 10, iters: 201, time: 0.104, data: 0.001) G_GAN: 1.572 G_L1: 20.248 D_real: 0.602 D_fake: 0.434 \n",
      "saving the model at the end of epoch 10, iters 2110\n",
      "End of epoch 10 / 200 \t Time Taken: 22 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 11, iters: 90, time: 0.103, data: 0.001) G_GAN: 1.679 G_L1: 23.120 D_real: 0.589 D_fake: 0.328 \n",
      "(epoch: 11, iters: 190, time: 0.105, data: 0.001) G_GAN: 2.246 G_L1: 21.723 D_real: 0.143 D_fake: 0.233 \n",
      "End of epoch 11 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 12, iters: 79, time: 0.250, data: 0.001) G_GAN: 2.081 G_L1: 24.542 D_real: 0.137 D_fake: 0.269 \n",
      "(epoch: 12, iters: 179, time: 0.103, data: 0.001) G_GAN: 1.098 G_L1: 19.187 D_real: 0.476 D_fake: 0.592 \n",
      "End of epoch 12 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 13, iters: 68, time: 0.104, data: 0.001) G_GAN: 0.419 G_L1: 16.047 D_real: 0.893 D_fake: 0.268 \n",
      "(epoch: 13, iters: 168, time: 0.104, data: 0.001) G_GAN: 1.114 G_L1: 21.200 D_real: 1.164 D_fake: 0.116 \n",
      "End of epoch 13 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 14, iters: 57, time: 0.242, data: 0.001) G_GAN: 1.015 G_L1: 17.218 D_real: 0.276 D_fake: 1.023 \n",
      "(epoch: 14, iters: 157, time: 0.105, data: 0.001) G_GAN: 1.862 G_L1: 22.652 D_real: 0.249 D_fake: 0.154 \n",
      "End of epoch 14 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 15, iters: 46, time: 0.104, data: 0.001) G_GAN: 2.891 G_L1: 23.760 D_real: 0.076 D_fake: 0.136 \n",
      "(epoch: 15, iters: 146, time: 0.105, data: 0.001) G_GAN: 1.137 G_L1: 18.662 D_real: 0.225 D_fake: 0.288 \n",
      "saving the model at the end of epoch 15, iters 3165\n",
      "End of epoch 15 / 200 \t Time Taken: 22 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 16, iters: 35, time: 0.256, data: 0.001) G_GAN: 0.440 G_L1: 22.681 D_real: 1.569 D_fake: 0.225 \n",
      "(epoch: 16, iters: 135, time: 0.106, data: 0.001) G_GAN: 0.881 G_L1: 17.152 D_real: 1.028 D_fake: 0.385 \n",
      "End of epoch 16 / 200 \t Time Taken: 13 sec\n",
      "learning rate = 0.0002000\n",
      "(epoch: 17, iters: 24, time: 0.104, data: 0.001) G_GAN: 1.510 G_L1: 22.090 D_real: 0.886 D_fake: 0.427 \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/ml/pix2pix_and_CycleGAN/train.py\", line 51, in <module>\n",
      "    model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
      "  File \"/home/ubuntu/ml/pix2pix_and_CycleGAN/models/pix2pix_model.py\", line 82, in set_input\n",
      "    self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Default setting includes flip which trains on left-right flips as well.\n",
    "#'--preprocess crop' allows user to load larger than 256X256 images and just randomly crop the right size for training.\n",
    "#  this is not as recommended because most of the crops will be just black with no information\n",
    "# If model is stuck, restart using --continue_train --epoch_count <number> to get numbering right.\n",
    "!python {code_main_folder}train.py --name pix2pix_2to1ratio --dataroot {train_patches_folder_combined} --model pix2pix --checkpoints_dir {root_path}checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Main test results can be viewed here: [~/ml/results/pix2pix_2to1ratio/test_latest/index.html](http://localhost:8888/view/ml/results/pix2pix_2to1ratio/test_latest/index.html) after test command\n",
    "\n",
    "Latent space values are visible here: [~/ml/results/pix2pix_2to1ratio/feats/center/](http://localhost:8888/tree/ml/results/pix2pix_2to1ratio/feats/center/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate combine train dataset of A and B\n",
    "image_combine_aux_functions.combine_images(\n",
    "    img_fold_A = (test_patches_folder + 'test_A/'),\n",
    "    img_fold_B = (test_patches_folder + 'test_B/'),\n",
    "    img_fold_AB = (test_patches_folder_combined + 'test/'))\n",
    "\n",
    "# Copy code patch to generate latent space\n",
    "shutil.copy('networks.py',os.path.expanduser(code_main_folder + \"models/\"))\n",
    "shutil.copy('pix2pix_model.py',os.path.expanduser(code_main_folder + \"models/\"))\n",
    "\n",
    "# Main test results + weights at the center\n",
    "#  --preprocess none allows to directly process a non 256x256 images using the convolutional proprety of the network\n",
    "!python {code_main_folder}test.py --name pix2pix_2to1ratio --dataroot {test_patches_folder_combined} --model pix2pix --checkpoints_dir {root_path}checkpoints --results_dir {root_path}results\n",
    "\n",
    "# Generate images and features on the train dataset as well\n",
    "!python {code_main_folder}test.py --name pix2pix_2to1ratio --dataroot {test_patches_folder_combined} --model pix2pix --checkpoints_dir {root_path}checkpoints --results_dir {root_path}results --phase train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_aws_neuron_pytorch_p36)",
   "language": "python",
   "name": "conda_aws_neuron_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
